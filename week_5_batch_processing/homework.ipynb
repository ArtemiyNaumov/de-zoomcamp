{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73823493-8d53-4f97-8075-39efb3977a71",
   "metadata": {},
   "source": [
    "## Week 5 Homework \n",
    "\n",
    "In this homework we'll put what we learned about Spark in practice.\n",
    "\n",
    "For this homework we will be using the FHVHV 2021-06 data found here. [FHVHV Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05709ce-eb40-47e8-b055-22d092c68901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-05 18:12:06--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230305T181206Z&X-Amz-Expires=300&X-Amz-Signature=90a6b90b87dcadf27d6fd292d38ae9212698ac9ed991fa5081232ac5fce9c62b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-05 18:12:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230305T181206Z&X-Amz-Expires=300&X-Amz-Signature=90a6b90b87dcadf27d6fd292d38ae9212698ac9ed991fa5081232ac5fce9c62b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 175799316 (168M) [application/octet-stream]\n",
      "Saving to: ‘fhvhv_tripdata_2021-06.csv.gz’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 167.66M  17.2MB/s    in 10s     \n",
      "\n",
      "2023-03-05 18:12:17 (16.7 MB/s) - ‘fhvhv_tripdata_2021-06.csv.gz’ saved [175799316/175799316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e7895-c51d-48eb-b4c3-21603b1cda3e",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "- 3.3.2\n",
    "- 2.1.4\n",
    "- 1.2.3\n",
    "- 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a47341-47ba-46d2-a131-1dd560b32833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c33ae44-3e84-4669-bb46-4a5d401fce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/05 18:09:35 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('homework') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a23ecd-cb74-4850-a273-ccd0f16c9e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409559b-88d7-4d2b-8355-26d7f04cc5bb",
   "metadata": {},
   "source": [
    "#### Answer: 3.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3a9ba-2d90-40a3-90ee-0ec63a51c927",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "\n",
    "**HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.</br> \n",
    "We will use this dataset for all the remaining questions.</br>\n",
    "Repartition it to 12 partitions and save it to parquet.</br>\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.</br>\n",
    "\n",
    "\n",
    "- 2MB\n",
    "- 24MB\n",
    "- 100MB\n",
    "- 250MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13325c3b-38f7-437e-8913-a0eef50ccd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc776196-b060-46e7-9be0-b934b4a57950",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv_schema = types.StructType([\n",
    "    types.StructField(\"dispatching_base_num\", types.StringType(), True),\n",
    "    types.StructField(\"pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"SR_Flag\", types.StringType(), True),\n",
    "    types.StructField(\"Affiliated_base_number\", types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5565122d-ee7c-443f-8194-426ade749916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhvhv_schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfb8ab6-a65d-49b2-b2c3-a7054b332905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02764|2021-06-01 00:02:41|2021-06-01 00:07:46|         174|          18|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:16:16|2021-06-01 00:21:14|          32|         254|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:27:01|2021-06-01 00:42:11|         240|         127|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:46:08|2021-06-01 00:53:45|         127|         235|      N|                B02764|\n",
      "|              B02510|2021-06-01 00:45:42|2021-06-01 01:03:33|         144|         146|      N|                  null|\n",
      "|              B02510|2021-06-01 00:18:15|2021-06-01 00:25:47|          49|          17|      N|                  null|\n",
      "|              B02510|2021-06-01 00:33:06|2021-06-01 00:42:46|          49|         225|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:27|2021-06-01 00:56:50|         225|         177|      N|                  null|\n",
      "|              B02764|2021-06-01 00:48:06|2021-06-01 01:04:10|         209|          45|      N|                B02764|\n",
      "|              B02875|2021-06-01 00:18:54|2021-06-01 00:26:14|          80|         256|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:31:02|2021-06-01 00:36:39|         217|          17|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:41:53|2021-06-01 01:07:32|          17|         265|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:29:52|2021-06-01 00:54:41|         210|          76|      N|                B02875|\n",
      "|              B02510|2021-06-01 00:15:57|2021-06-01 00:39:36|         226|         213|      N|                  null|\n",
      "|              B02510|2021-06-01 00:11:59|2021-06-01 00:23:32|         191|           9|      N|                  null|\n",
      "|              B02510|2021-06-01 00:30:35|2021-06-01 00:45:35|          16|         250|      N|                  null|\n",
      "|              B02510|2021-06-01 00:49:01|2021-06-01 01:03:50|         182|         259|      N|                  null|\n",
      "|              B02510|2021-06-01 00:07:36|2021-06-01 00:21:13|         188|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:25:48|2021-06-01 00:40:43|          39|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:11|2021-06-01 00:53:39|          72|          35|      N|                  null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbe6ece3-6eba-40f5-8190-bbc9a0455c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .repartition(12) \\\n",
    "    .write.parquet('fhvhv_tripdata_2021-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c086e14-70d7-4eb4-a1c1-6660690c8782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 284M\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov   0 Mar  5 18:20 _SUCCESS\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00000-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00001-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00002-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00003-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00004-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00005-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00006-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00007-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00008-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00009-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00010-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ArtemiyNaumov ArtemiyNaumov 24M Mar  5 18:20 part-00011-4e86b37c-575e-43f1-9a86-9ca91d23fca0-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./fhvhv_tripdata_2021-06/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a779893-1223-457b-ab32-324b8174b116",
   "metadata": {},
   "source": [
    "#### Answer: 24MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf8adf-be7c-4700-989d-2ae70b13ad41",
   "metadata": {},
   "source": [
    "### Question 3: \n",
    "\n",
    "**Count records**  \n",
    "\n",
    "How many taxi trips were there on June 15?</br></br>\n",
    "Consider only trips that started on June 15.</br>\n",
    "\n",
    "- 308,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 50,982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b15e266-d89c-4b86-a21b-d91056ad65ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ArtemiyNaumov/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhvhv_trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be5a8893-4641-4e54-81a1-5c960883da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT \n",
    "        COUNT(1)\n",
    "    FROM fhvhv_trips_data\n",
    "    WHERE CAST(pickup_datetime AS DATE) = '2021-06-15'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "998ae1aa-b409-4009-b0fe-a1191729fb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  452470|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "036a1efe-e2bd-4b58-ac96-2ae162a4cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d2fd4f8-08e9-4115-94a8-286f5fb3ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(F.to_date(F.col('pickup_datetime')) == F.lit('2021-06-15')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b013e-9534-41e2-aa6a-8dd89b29480a",
   "metadata": {},
   "source": [
    "#### Answer: 452,470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6153e6-44d1-473d-bfb4-2f4f732bed3a",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day**  \n",
    "\n",
    "Now calculate the duration for each trip.</br>\n",
    "How long was the longest trip in Hours?</br>\n",
    "\n",
    "- 66.87 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13c2d04f-1ccb-4389-b555-2d69cdacfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = '''\n",
    "    SELECT\n",
    "        CAST(TIMESTAMPDIFF(SECOND, pickup_datetime, dropoff_datetime) AS NUMERIC) / 3600 AS trip_duration_in_hours\n",
    "    FROM fhvhv_trips_data\n",
    "    ORDER BY 1 DESC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4aa5538-dc1b-49d6-8363-b828f0075b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|trip_duration_in_hours|\n",
      "+----------------------+\n",
      "|             66.878889|\n",
      "|             25.549722|\n",
      "|             19.980833|\n",
      "|             18.197222|\n",
      "|             16.466944|\n",
      "|             14.268889|\n",
      "|             13.909722|\n",
      "|             11.670000|\n",
      "|             11.365833|\n",
      "|             10.984444|\n",
      "|             10.267500|\n",
      "|              9.966389|\n",
      "|              9.966389|\n",
      "|              9.637778|\n",
      "|              9.624444|\n",
      "|              9.480278|\n",
      "|              9.471667|\n",
      "|              9.402222|\n",
      "|              9.393611|\n",
      "|              9.376944|\n",
      "+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(query_2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bde47-c36a-4b8a-852c-76bef1376333",
   "metadata": {},
   "source": [
    "#### Answer: 66.87 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ff652-39c9-4cae-842d-4d15b97f1999",
   "metadata": {},
   "source": [
    "### Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    " Spark’s User Interface which shows application's dashboard runs on which local port?</br>\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc368e79-81e0-41ed-a1fc-f531ea81432a",
   "metadata": {},
   "source": [
    "#### Answer: 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8eee3-fe2b-491b-9193-50526cd5b04e",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)</br>\n",
    "\n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Astoria\n",
    "- Union Sq\n",
    "- Crown Heights North"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2fb4cdc-7f55-4c82-ad0a-560ba4cab6ce",
   "metadata": {},
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f26eff6-5480-4119-b6ff-cd89857784e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79bbd093-c820-4704-b5db-15d9ff0955b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0ea174d-ba2c-4adc-972c-70eaa23f1e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ArtemiyNaumov/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3d680ad-10e1-46b6-9af6-e5e7a6d09e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3 = '''\n",
    "    SELECT \n",
    "        pickup_zone.Zone,\n",
    "        count(1) as cnt_\n",
    "    FROM fhvhv_trips_data\n",
    "    JOIN zones AS pickup_zone ON\n",
    "        fhvhv_trips_data.PULocationID = pickup_zone.LocationID\n",
    "    GROUP BY 1 ORDER BY 2 DESC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d425e5e-7840-40c4-bbae-836c62ec961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                Zone|  cnt_|\n",
      "+--------------------+------+\n",
      "| Crown Heights North|231279|\n",
      "|        East Village|221244|\n",
      "|         JFK Airport|188867|\n",
      "|      Bushwick South|187929|\n",
      "|       East New York|186780|\n",
      "|TriBeCa/Civic Center|164344|\n",
      "|   LaGuardia Airport|161596|\n",
      "|            Union Sq|158937|\n",
      "|        West Village|154698|\n",
      "|             Astoria|152493|\n",
      "|     Lower East Side|151020|\n",
      "|        East Chelsea|147673|\n",
      "|Central Harlem North|146402|\n",
      "|Williamsburg (Nor...|143683|\n",
      "|          Park Slope|143594|\n",
      "|  Stuyvesant Heights|141427|\n",
      "|        Clinton East|139611|\n",
      "|West Chelsea/Huds...|139431|\n",
      "|             Bedford|138428|\n",
      "|         Murray Hill|137879|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(query_3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b96e0-cdc6-49c3-b49b-2bf5c6aa56b5",
   "metadata": {},
   "source": [
    "#### Answer: Crown Heights North"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
